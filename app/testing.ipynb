{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:yfinance:Entering download()\n",
      "DEBUG:yfinance:Disabling multithreading because DEBUG logging enabled\n",
      "DEBUG:yfinance: Entering history()\n",
      "DEBUG:peewee:('SELECT \"t1\".\"key\", \"t1\".\"value\" FROM \"_kv\" AS \"t1\" WHERE (\"t1\".\"key\" = ?) LIMIT ? OFFSET ?', ['AAPL', 1, 0])\n",
      "DEBUG:yfinance:  Entering history()\n",
      "DEBUG:yfinance:AAPL: Yahoo GET parameters: {'period1': '2024-08-02 20:20:27-04:00', 'period2': '2024-08-05 20:20:27-04:00', 'interval': '1m', 'includePrePost': False, 'events': 'div,splits,capitalGains'}\n",
      "DEBUG:yfinance:   Entering get()\n",
      "DEBUG:yfinance:url=https://query2.finance.yahoo.com/v8/finance/chart/AAPL\n",
      "DEBUG:yfinance:params={'period1': 1722644427, 'period2': 1722903627, 'interval': '1m', 'includePrePost': False, 'events': 'div,splits,capitalGains'}\n",
      "DEBUG:yfinance:    Entering _get_cookie_and_crumb()\n",
      "DEBUG:yfinance:cookie_mode = 'basic'\n",
      "DEBUG:yfinance:     Entering _get_cookie_and_crumb_basic()\n",
      "DEBUG:yfinance:reusing cookie\n",
      "DEBUG:yfinance:reusing crumb\n",
      "DEBUG:yfinance:     Exiting _get_cookie_and_crumb_basic()\n",
      "DEBUG:yfinance:    Exiting _get_cookie_and_crumb()\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: query2.finance.yahoo.com\n",
      "DEBUG:urllib3.connectionpool:https://query2.finance.yahoo.com:443 \"GET /v8/finance/chart/AAPL?period1=1722644427&period2=1722903627&interval=1m&includePrePost=False&events=div%2Csplits%2CcapitalGains&crumb=L9phYW3JoCQ HTTP/11\" 200 None\n",
      "DEBUG:yfinance:response code=200\n",
      "DEBUG:yfinance:   Exiting get()\n",
      "DEBUG:yfinance:AAPL: yfinance received OHLC data: 2024-08-05 13:30:00 -> 2024-08-05 18:20:24\n",
      "DEBUG:yfinance:AAPL: OHLC after cleaning: 2024-08-05 09:30:00-04:00 -> 2024-08-05 14:20:00-04:00\n",
      "DEBUG:yfinance:AAPL: OHLC after combining events: 2024-08-05 09:30:00-04:00 -> 2024-08-05 14:20:00-04:00\n",
      "DEBUG:yfinance:AAPL: yfinance returning OHLC: 2024-08-05 09:30:00-04:00 -> 2024-08-05 14:20:00-04:00\n",
      "DEBUG:yfinance:  Exiting history()\n",
      "DEBUG:yfinance: Exiting history()\n",
      "DEBUG:yfinance:Exiting download()\n",
      "c:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\app\\model_classes\\RNN_model_class.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df.columns]= scaler_X.transform(df[df.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train_Loss: 0.0389\n",
      "Epoch [10/100], Test_Loss: 0.0856\n",
      "Epoch [20/100], Train_Loss: 0.0127\n",
      "Epoch [20/100], Test_Loss: 0.0147\n",
      "Epoch [30/100], Train_Loss: 0.0021\n",
      "Epoch [30/100], Test_Loss: 0.0020\n",
      "Epoch [40/100], Train_Loss: 0.0033\n",
      "Epoch [40/100], Test_Loss: 0.0019\n",
      "Epoch [50/100], Train_Loss: 0.0033\n",
      "Epoch [50/100], Test_Loss: 0.0008\n",
      "Epoch [60/100], Train_Loss: 0.0026\n",
      "Epoch [60/100], Test_Loss: 0.0021\n",
      "Epoch [70/100], Train_Loss: 0.0022\n",
      "Epoch [70/100], Test_Loss: 0.0007\n",
      "Epoch [80/100], Train_Loss: 0.0021\n",
      "Epoch [80/100], Test_Loss: 0.0013\n",
      "Epoch [90/100], Train_Loss: 0.0020\n",
      "Epoch [90/100], Test_Loss: 0.0008\n",
      "Epoch [100/100], Train_Loss: 0.0020\n",
      "Epoch [100/100], Test_Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import model_classes.RNN_model_class as RNN_model_class\n",
    "import yaml\n",
    "import main\n",
    "\n",
    "yaml_path = 'train_params.yaml'\n",
    "with open(yaml_path, 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "params['data_params']['ticker'] = 'AAPL'\n",
    "model = None\n",
    "scaler_X = None\n",
    "scaler_Y = None\n",
    "    \n",
    "RNN_model = RNN_model_class.RNN_model(params, model, scaler_X, scaler_Y)\n",
    "model, scaler_X, scaler_Y, params = RNN_model.train_model()\n",
    "main.save_training(model, scaler_X, scaler_Y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\Model_DB\n",
      "Number of folders exceeds 10. Total folders: 2\n",
      "Successfully deleted the folder and all its contents: C:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\Model_DB\\AAPL_RNN_19.02\n",
      "Successfully deleted the folder and all its contents: C:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\Model_DB\\AAPL_RNN_19.27\n",
      "All folders have been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.isdir(folder_path):\n",
    "        try:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"Successfully deleted the folder and all its contents: {folder_path}\")\n",
    "            success = True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Folder not found: {folder_path}\")\n",
    "            success = False\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: {folder_path}\")\n",
    "            success = False\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "            success = False\n",
    "    else:\n",
    "        print(f\"The path is not a directory: {folder_path}\")\n",
    "        success = False\n",
    "    return success\n",
    "\n",
    "\n",
    "\n",
    "def manage_folders(base_dir):\n",
    "    \n",
    "    base_path = Path(base_dir)\n",
    "    # Get a list of all directories in the base directory\n",
    "    folders = [folder for folder in base_path.iterdir() if folder.is_dir()]\n",
    "    \n",
    "    # Check if the number of folders exceeds 10\n",
    "    if len(folders) >= 2:\n",
    "        print(f\"Number of folders exceeds 10. Total folders: {len(folders)}\")\n",
    "        for folder in folders:\n",
    "            delete_folder(folder)  # Delete each folder\n",
    "        print(\"All folders have been deleted.\")\n",
    "    else:\n",
    "        print(f\"Number of folders is within limit. Total folders: {len(folders)}\")\n",
    "\n",
    "\n",
    "#set baser_dir to current path \n",
    "MODEL_DB_DIR = r'C:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\Model_DB'\n",
    "\n",
    "\n",
    "\n",
    "print(MODEL_DB_DIR)\n",
    "manage_folders(MODEL_DB_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variable for older predictions \n",
    "all_preds = {'Datetime': [], 'Prediction': [], 'Model_name': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Datetime  AAPL_RNN_20.06  AAPL_RNN_20.23       Close\n",
      "0  2024-08-05 15:00:00-04:00             NaN             NaN  204.619995\n",
      "1  2024-08-05 15:01:00-04:00             NaN             NaN  204.095001\n",
      "2  2024-08-05 15:02:00-04:00             NaN             NaN  205.331604\n",
      "3  2024-08-05 15:03:00-04:00             NaN             NaN  205.919998\n",
      "4  2024-08-05 15:04:00-04:00             NaN             NaN  206.350006\n",
      "..                       ...             ...             ...         ...\n",
      "57 2024-08-05 15:57:00-04:00             NaN             NaN  208.610001\n",
      "58 2024-08-05 15:58:00-04:00             NaN             NaN  208.940002\n",
      "59 2024-08-05 15:59:00-04:00             NaN             NaN  209.190002\n",
      "60 2024-08-05 16:01:00-04:00      204.487457             NaN         NaN\n",
      "61 2024-08-05 16:02:00-04:00             NaN      214.159973         NaN\n",
      "\n",
      "[62 rows x 4 columns]\n",
      "Empty DataFrame\n",
      "Columns: [Datetime, AAPL_RNN_20.06, AAPL_RNN_20.23, Close]\n",
      "Index: []\n",
      "{'AAPL_RNN_20.06': None, 'AAPL_RNN_20.23': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\app\\model_classes\\RNN_model_class.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[features.columns] = self.scaler_X.transform(features[features.columns])\n",
      "c:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\app\\model_classes\\RNN_model_class.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[features.columns] = self.scaler_X.transform(features[features.columns])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import helper_fct\n",
    "import model_classes.RNN_model_class as RNN_model_class\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "def predict_model( data, model_name):\n",
    "    # set folder dir for model\n",
    "    model = RNN_model_class.RNN_model()\n",
    "    model.load_model(model_name=model_name,model_db=MODEL_DB_DIR)\n",
    "    prediction = model.predict(data)\n",
    "\n",
    "    return prediction\n",
    "MODEL_DB_DIR = r'C:\\Users\\phili\\OneDrive\\Projekte\\Code\\GitHub\\timeseries_forcast_in_finance_MLops\\Model_DB'\n",
    "ticker  = 'AAPL'\n",
    "model_list = ['AAPL_RNN_20.06','AAPL_RNN_20.23']\n",
    "mse_dict = {}\n",
    "\n",
    "# load prediction data \n",
    "data = helper_fct.get_predict_data(ticker=ticker, interval='1m', seq_length=60)\n",
    "#print(data)\n",
    "plot_data = data['Close'].reset_index()\n",
    "\n",
    "# refactor datetime to the same timezone for merging \n",
    "plot_data['Datetime'] = pd.to_datetime(plot_data['Datetime'], utc=True)\n",
    "plot_data['Datetime'] = plot_data['Datetime'].dt.tz_convert('America/New_York')\n",
    "\n",
    "for model_name in model_list :\n",
    "    # predict with the model\n",
    "    prediction = predict_model(data=data, model_name=model_name)\n",
    "\n",
    "    all_preds['Datetime'].append(prediction['Datetime'])\n",
    "    all_preds['Prediction'].append(prediction['Prediction'])\n",
    "    all_preds['Model_name'].append(model_name)\n",
    "\n",
    "        \n",
    "# refactor df so that it has the structure:\n",
    "# Datetime      Model_name_A            Model_name_B              Close\n",
    "# date          prediction_model A      prediction_model B        actual_price\n",
    "df_plot = pd.DataFrame(all_preds)\n",
    "\n",
    "# refactor datetime to the same timezone for merging \n",
    "df_plot['Datetime'] = pd.to_datetime(df_plot['Datetime'], utc=True)\n",
    "df_plot['Datetime'] = df_plot['Datetime'].dt.tz_convert('America/New_York')\n",
    "\n",
    "# merging both dataframes \n",
    "df_plot = df_plot.drop_duplicates(subset=['Datetime', 'Model_name'])               \n",
    "pivoted_df = df_plot.pivot(index='Datetime', columns='Model_name', values='Prediction').reset_index()\n",
    "plot_data = pd.merge(pivoted_df, plot_data, on=\"Datetime\", how='outer').sort_values(by='Datetime').reset_index(drop=True)\n",
    "print(plot_data)\n",
    "# calculate MSE\n",
    "df_mse = plot_data.dropna()\n",
    "for model_name in model_list :\n",
    "    if df_mse.empty:\n",
    "        mse_dict[model_name] = None\n",
    "            \n",
    "    else :\n",
    "        mse_dict[model_name] = MAE(df_mse['Close'],df_mse[model_name])\n",
    "\n",
    "print(df_mse)\n",
    "print(mse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main \n",
    "\n",
    "   df_mse = plot_data.dropna()\n",
    "    for model_name in model_list :\n",
    "        if df_mse.empty:\n",
    "            mae_dict[model_name] = None\n",
    "            \n",
    "        else :\n",
    "            mae_dict[model_name] = MAE(df_mse['Close'],df_mse[model_name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
